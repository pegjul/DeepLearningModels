{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as tfl\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons import layers as tfal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/kaggle_datasets/plant-pathology-2021-fgvc8/train.csv', index_col='image').to_dict()\n",
    "data = df['labels']\n",
    "keys=[\"healthy\", \"scab\", \"frog_eye_leaf_spot\", \"rust\", \"complex\", \"powdery_mildew\"]\n",
    "\n",
    "def text_to_vec(value, keys):\n",
    "    out = np.zeros(len(keys), np.float32)\n",
    "    for i, key in enumerate(keys):\n",
    "        if key in value:\n",
    "            out[i] = 1\n",
    "    assert out.sum() > 0, print(value, out)\n",
    "    return out\n",
    "\n",
    "for img in data:\n",
    "    data[img] = text_to_vec(data[img], keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "images = list(data.keys())\n",
    "random.shuffle(images)\n",
    "test_train_slpit = 5/95\n",
    "img_shape = 256\n",
    "\n",
    "def normalize(img):\n",
    "    return img/255\n",
    "\n",
    "def resize(img):\n",
    "    long_side = max(img.size)\n",
    "    ratio = img_shape / long_side\n",
    "    new_shape = (int(img.width*ratio), int(img.height*ratio))\n",
    "    return img.resize(new_shape)\n",
    "\n",
    "def padding(img):\n",
    "    height_pad = (img_shape - img.shape[0])/2\n",
    "    height_pad_f = int(np.floor(height_pad))\n",
    "    height_pad_c = int(np.ceil(height_pad))\n",
    "    width_pad = (img_shape - img.shape[1])/2\n",
    "    width_pad_f = int(np.floor(width_pad))\n",
    "    width_pad_c = int(np.ceil(width_pad))\n",
    "    pad = ((height_pad_f, height_pad_c), (width_pad_f, width_pad_c), (0, 0))\n",
    "    return np.pad(img, pad, 'constant', constant_values=0.5)\n",
    "\n",
    "def gen(start, end):\n",
    "    for img in images[start:end]:\n",
    "        I = Image.open(os.path.join(\"/home/julian/kaggle_datasets/plant-pathology-2021-fgvc8/train_images\", img))\n",
    "        I = resize(I)\n",
    "        I = np.array(I, np.float32)\n",
    "        I = normalize(I)\n",
    "        I = padding(I)\n",
    "        yield I, data[img]\n",
    "\n",
    "        \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "batch_size = 32\n",
    "global_batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "\n",
    "output_signature=(tf.TensorSpec(shape=(img_shape, img_shape, 3), dtype=tf.float32), tf.TensorSpec(shape=(len(keys)), dtype=tf.float32))\n",
    "train_start = 0\n",
    "train_end = int(len(images) * (1 - test_train_slpit))\n",
    "test_start = train_end\n",
    "test_end = len(images) + 1\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(gen, output_signature=output_signature, \n",
    "                  args=(train_start, train_end)).shuffle(batch_size).cache().prefetch(tf.data.AUTOTUNE).batch(global_batch_size)\n",
    "test_dataset = tf.data.Dataset.from_generator(gen, output_signature=output_signature, \n",
    "                  args=(train_start, train_end)).cache().prefetch(tf.data.AUTOTUNE).batch(global_batch_size)\n",
    "\n",
    "steps_per_epoch_train = np.ceil(train_end/batch_size)\n",
    "steps_per_epoch_test = np.ceil((test_end - test_start)/batch_size)\n",
    "\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_heads = 4, transformer_layers = 8, mlp_head_units = [256, 128]):\n",
    "\n",
    "    def residual(inp, filters):\n",
    "        x = tfl.Conv2D(filters, 3, padding=\"same\")(inp)\n",
    "        x = tfal.GELU()(x)\n",
    "        x = tfl.Conv2D(filters*2, 1)(x)\n",
    "        x = tfal.GELU()(x)\n",
    "        x = tfl.Concatenate()([x, inp])\n",
    "        x = tfl.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = tfl.Conv2D(filters, 3, 2, padding=\"same\")(x)\n",
    "        x = tfal.GELU()(x)\n",
    "        return x\n",
    "\n",
    "    def mlp(x, hidden_units, dropout_rate):\n",
    "        for units in hidden_units:\n",
    "            x = tfl.Dense(units, activation=tf.nn.gelu)(x)\n",
    "            x = tfl.Dropout(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    class PositionalEncoding(tfl.Layer):\n",
    "        def __init__(self, num_patches, projection_dim):\n",
    "            super(PositionalEncoding, self).__init__()\n",
    "            self.projection = tfl.Dense(units=projection_dim)\n",
    "            self.position_embedding = tfl.Embedding(\n",
    "                input_dim=num_patches, output_dim=projection_dim\n",
    "            )\n",
    "            self.positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            positional_encoding = self.projection(inputs) + self.position_embedding(self.positions)\n",
    "            return positional_encoding\n",
    "\n",
    "    inp = tf.keras.Input(shape=(img_shape, img_shape, 3))\n",
    "    x = residual(inp, 8)\n",
    "    x = residual(x, 16)\n",
    "    x = residual(x, 32)\n",
    "    x = residual(x, 64)\n",
    "    x = tfl.Reshape((-1, 64))(x)\n",
    "    projection_dim = x.shape[-1]\n",
    "    num_patches = x.shape[-2]\n",
    "    x = PositionalEncoding(num_patches, projection_dim)(x)\n",
    "    transformer_units = [\n",
    "        projection_dim * 2,\n",
    "        projection_dim,\n",
    "    ]\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "            x1 = tfl.LayerNormalization(epsilon=1e-6)(x)\n",
    "            # Create a multi-head attention layer.\n",
    "            attention_output = tfl.MultiHeadAttention(\n",
    "                num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "            )(x1, x1)\n",
    "            # Skip connection 1.\n",
    "            x2 = tfl.Add()([attention_output, x])\n",
    "            # Layer normalization 2.\n",
    "            x3 = tfl.LayerNormalization(epsilon=1e-6)(x2)\n",
    "            # MLP.\n",
    "            x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "            # Skip connection 2.\n",
    "            x = tfl.Add()([x3, x2])\n",
    "\n",
    "    x = tfl.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = tfl.Flatten()(x)\n",
    "    x = tfl.Dropout(0.5)(x)\n",
    "    x = mlp(x, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    x = tfl.Dense(len(keys))(x)\n",
    "\n",
    "    return tf.keras.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/.conda/envs/tf/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:390: UserWarning: Default value of `approximate` is changed from `True` to `False`\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = \"./tmp/checkpoint\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_filepath, \"ckpt\")\n",
    "\n",
    "with strategy.scope():\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "    def compute_loss(y, y_):\n",
    "        return loss_fn(y, y_)\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name='loss')\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_binary_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_binary_accuracy')\n",
    "\n",
    "    model = create_model()\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "\n",
    "def train_step(inputs):\n",
    "    images, labels = inputs\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images, training=True)\n",
    "        loss = compute_loss(labels, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss.update_state(loss)\n",
    "    train_accuracy.update_state(labels, predictions)\n",
    "    return loss \n",
    "\n",
    "def test_step(inputs):\n",
    "    images, labels = inputs\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = compute_loss(labels, predictions)\n",
    "    test_loss.update_state(t_loss)\n",
    "    test_accuracy.update_state(labels, predictions)\n",
    "    \n",
    "\n",
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                         axis=None)\n",
    "\n",
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "    return strategy.run(test_step, args=(dataset_inputs,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [>                                                  ] Loss: 16.77162742614746, Binary_Accuracy: 81.4350357055664, Test Loss: 0.0, Test Binary_Accuracy: 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "template = (\"Epoch {}/{} [{}{}{}] Loss: {}, Binary_Accuracy: {}, Test Loss: {}, Test Binary_Accuracy: {}\")\n",
    "for epoch in range(num_epochs):\n",
    "    print(template.format(epoch+1,\n",
    "                          num_epochs,\n",
    "                          \"\",\n",
    "                          \">\",\n",
    "                          \" \"*50,\n",
    "                          test_loss.result(),\n",
    "                          train_accuracy.result()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100),\n",
    "                          end=\"\\r\")\n",
    "    for i, x in enumerate(train_dist_dataset):\n",
    "        percent = int(i//steps_per_epoch_train)\n",
    "        distributed_train_step(x)\n",
    "        print(\" \"*1000, end=\"\\r\")\n",
    "        print(template.format(epoch+1,\n",
    "                          num_epochs,\n",
    "                          \"=\"*(percent//2),\n",
    "                          \">\" if percent < 100 else \"\",\n",
    "                          \" \"*(50 - percent//2),\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100),\n",
    "                          end=\"\\r\")\n",
    "        \n",
    "    # TEST LOOP\n",
    "    for i, x in enumerate(test_dist_dataset):\n",
    "        percent = i//steps_per_epoch_test\n",
    "        distributed_test_step(x)\n",
    "        print(\" \"*1000, end=\"\\r\")\n",
    "        print(template.format(epoch+1,\n",
    "                          num_epochs,\n",
    "                          \"=\"*percent//2,\n",
    "                          \">\" if percent < 100 else \"\",\n",
    "                          \" \"*(50 - percent//2),\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result()*100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100)\n",
    "                          , end=\"\\r\")\n",
    "\n",
    "    if test_accuracy.result() > best_accuracy:\n",
    "        best_accuracy = test_accuracy.result()\n",
    "        checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
